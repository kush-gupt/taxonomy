version: 3
domain: Scheduling
created_by: kush-gupt
document_outline: |
  Overview of the Flux scheduler, explaining what it is, how
  they came to be, and the relationship with High Performance
  Computing and cloud native technologies.

document:
  repo: https://github.com/kush-gupt/taxonomy-knowledge-docs.git
  commit: 96f6517a5abe0255c237e942f6e4cbdcbf99e51c
  patterns:
    - '*.pdf'

# Flux 2014 Starter ----------------------------------------------------------------------------------------------------
seed_examples:
  - context: |-
      An HPC batch system must generate and provide a complete set of statistics for
      the jobs that are run and the resources that are consumed.  This begins with a
      list of job records, both individual and aggregated.  Users and managers will
      want to look back over time to see what jobs ran, what resources they ran on,
      and whether they ran successfully to completion.  Managers also require reports
      of how computing resource investments are utilized and by which users, groups
      and projects.  Fair-share calculations are based off the difference between what
      resources were promised and which resources were ultimately used.
    questions_and_answers:
      - question: What's one responsibility of an HPC batch system?
        answer: |-
          An HPC batch system generates and provides complete statistics
          for jobs run and resources consumed.
      - question: |-
          What information can be obtained from the job records provided by an HPC
          batch system?
        answer: |-
          Job records should show what jobs ran, resources used, and completion status.
      - question: |-
          How are fair-share calculations determined?
        answer: |-
          Fair-share calculations are based on differences
          between promised and actually used resources.
  - context: |-
      This primer introduces the concepts of High Performance Computing, scheduling,
      and resource management.  It focuses first on the state of the art and then
      introduces the issues under consideration in the design of a next generation
      resource manager known as Flux.  The Flux design addresses not just the
      challenges of resource management at a much larger scale of systems, but it also
      enables and promotes a much broader and richer model that invites collaboration
      with areas whose requirements cannot be met in current systems.
    questions_and_answers:
      - question: What main aspects does Flux's design address?
        answer: |-
          Flux addresses resource management at larger system scales and enables
          collaboration with areas unmet by current systems.
      - question: Why was Flux designed?
        answer: |-
          The Flux resource manager was designed to address the challenges of resource
          management at a larger scale of systems and to enable and promote collaboration
          with areas whose requirements are unmet in current systems.
      - question: How does Flux differ from traditional resource management approaches?
        answer: |-
          Flux provides a hierarchical, fully-nested framework where each job
          is a complete instance, allowing flexible resource allocation and
          customizable scheduling policies.
  - context: |-
      The term High performance computing (HPC) as it is commonly used refers to a
      category of computing systems that combine computing power from multiple units
      to deliver vastly higher performance than desktop computers can provide.  HPC is
      distinguished not just by computing power.  HPC systems are designed to run a
      variety of large applications for extended periods of time in order to solve
      complex problems.  HPC is distinguished from web servers in that they dedicate
      requested resources to run applications provided by users.  Current HPC systems
      are distinguished from cloud services like AWS in that they generally provide a
      single operating system with a runtime environment managed by the facility.
    questions_and_answers:
      - question: What's commonly understood by 'High performance computing'?
        answer: |-
          HPC refers to computing systems combining power from multiple units
          for vastly higher performance than desktop computers.
      - question: How does HPC differ from web servers and cloud services?
        answer: |-
          HPC dedicates resources to user applications, unlike web servers,
          and provides a single facility-managed operating environment,
          unlike cloud services.
      - question: |-
          Why are HPC systems better for complex long-term problems?
        answer: |-
          They're designed to run large applications for extended periods
          to solve complex problems.
# Flux 2018 ----------------------------------------------------------------------------------------------------
  - context: |-
      System-level solutions can be broken down into centralized, limited
      hierarchical, and decentralized schedulers. Centralized schedulers use a single,
      global scheduler that maintains and tracks the full knowledge of jobs and
      resources to make scheduling decisions. This scheduling model is simple and
      effective for moderate-size clusters, making it the state of the practice in
      most cloud and HPC centers today. Cloud schedulers such as Swarm [18] and
      Kubernetes [19] and HPC schedulers such as SLURM [8], MOAB [10], LSF [9], and
      PBSPro [11] are centralized. While simple, these centralized schedulers are
      capped at tens of jobs/sec [25], provide limited to no support for co-scheduling
      of heterogeneous tasks [26], have limited APIs, and cannot be easily nested
      within other system schedulers.
    questions_and_answers:
      - question: What scheduling model do centralized schedulers use?
        answer: |-
          They use a single global scheduler tracking full knowledge of jobs and resources.
      - question: |-
          What scheduling model suits high job volumes and heterogeneous tasks?
        answer: |-
          A decentralized model would better handle many jobs and support co-scheduling heterogeneous tasks.
      - question: What limits centralized schedulers like SLURM and LSF?
        answer: |-
          They're capped at tens of jobs/second, lack heterogeneous task co-scheduling, have limited APIs,
          and can't nest in other schedulers.
  - context: |-
      Flux's user-driven, customizable approach to scheduling provides inherent
      support for co-scheduling. Flux's flexible design allows users to decide whether
      or not co-scheduling should be configured and also lets users choose their own
      scheduling policies within the scope of an instance. With the help of the job
      submission API, several tasks can efficiently coexist on a single node without
      any restrictions on their number, type, or resource requirements. This allows
      for submission and tuning at all possible levels of heterogeneity within a node
      (and across nodes), including individual cores, a set of cores, sockets, GPUs,
      or burst buffers.
    questions_and_answers:
      - question: Does Flux support co-scheduling?
        answer: Yes, Flux supports co-scheduling.
      - question: What are Flux's key scheduling features?
        answer: |-
          User-driven, customizable scheduling with co-scheduling support, user-chosen policies,
          and job submission enabling multiple tasks regardless of type or requirements.
      - question: |-
          Why might users choose Flux for scheduling?
        answer: |-
          It allows for efficient coexistence of several tasks on a node without restrictions on
          their number, type, or resource requirements. This flexibility enables
          submission and tuning at all possible levels of heterogeneity within a node and
          across nodes, including individual cores, sets of cores, sockets, GPUs, or burst
          buffers.
# Fluxion 2023 ----------------------------------------------------------------------------------------------------
  - context: |-
      We presented a novel graph-based resource model and its implementation, Fluxion,
      for HPC and converged computing scheduling. Our model addresses the limitations
      of existing node-centric models, and supports converged computing environments,
      disaggregated systems, and complex and elastic modern workflows. We described
      the novel architecture, procedures for improving scalability, and algorithms
      comprising Fluxion and discussed how these contributions allow Fluxion to
      schedule resources efficiently. We discussed several emerging use cases which
      our model enables and evaluated its scalability. Future work involves optimizing
      our model's implementation and applying it to scheduling environments with
      dynamic resources and hierarchies. The powerful combination of a directed-graph
      resource model with fully-hierarchical scheduling and architectural separation
      of concerns allows Fluxion to schedule virtually any resource types, including
      types not yet devised.
    questions_and_answers:
      - question: |-
          What makes Fluxion suitable for converged computing?
        answer: |-
          Its directed-graph resource model with hierarchical scheduling
          and separation of concerns handles virtually any resource types.
      - question: |-
          Why is Fluxion well-suited for dynamic environments?
        answer: |-
           Its adaptable, flexible directed-graph model with hierarchical
           scheduling handles dynamic resources effectively.
      - question: What is Fluxion's relation to Flux?
        answer: |-
          Fluxion is Flux's graph-based scheduler component
          implementing a novel resource model, formerly called flux-sched.
  - context: |-
      In this changing landscape, HPC resource managers and job schedulers relying on
      restrictive approaches to solve emerging problems create a technology gap. One
      such gap is in the design of resource models , which define how information
      about resource types and job requests is stored internally. Existing HPC
      schedulers use a node-centric or core-centric design. While such a design is
      ideal for traditional applications and is efficient in terms of scheduler
      performance, it falls short in supporting emerging HPC workloads. For example,
      it does not offer natural ways to express resource relationships. As a result,
      it cannot be used to represent complex resource constraints or to capture
      elasticity that is inherent to modern workloads. It also cannot be extended
      easily to represent extremely heterogeneous resources or flow resources such as
      power or network bandwidth. Such a design also limits expressibility for
      seamless scheduling across disaggregated resources or converged HPC and Cloud
      platforms [9, 28, 30].
    questions_and_answers:
      - question: What design do existing HPC schedulers use?
        answer: Node-centric or core-centric design.
      - question: |-
          What limits current HPC schedulers for emerging workloads?
        answer: |-
          They can't express resource relationships, represent complex constraints,
          capture elasticity, extend to heterogeneous resources, or schedule across platforms.
      - question: |-
          What design better supports emerging HPC workloads?
        answer: |-
          One expressing resource relationships, representing complex constraints,
          capturing elasticity, and scheduling across disaggregated resources or converged platforms.
# Flux FAQ ----------------------------------------------------------------------------------------------------
  - context: |-
      Flux is a new resource manager and job scheduler for high-performance computing
      (HPC) systems. It is designed to be flexible, scalable, and efficient, addressing
      the challenges of modern HPC workloads and enabling new use cases.
    questions_and_answers:
      - question: What is Flux?
        answer: |-
          A new resource manager and job scheduler for HPC systems designed for
          flexibility, scalability, and efficiency.
      - question: What are Flux's main goals?
        answer: |-
          Provide flexible, scalable resource management for HPC, address modern workload challenges, and enable new use cases.
      - question: |-
          What's Flux's resource allocation approach?
        answer: |-
          Hierarchical, multi-level management with graph-based resource model,
          enabling sophisticated scheduling beyond node-centric views.
# Flux Operator ----------------------------------------------------------------------------------------------------
  - context: |-
      This paper introduces the Flux Operator, 19 the next step in work to explore
      integration of a traditional HPC scheduler within Kubernetes. The Flux Operator
      is a Kubernetes operator 20 that handles all the setup and configuration of a
      fully fledged Flux cluster inside of Kubernetes itself, allowing the user to
      efficiently bring up and down an entire HPC cluster for a scoped set of work
      that optimizes for important aspects of HPC. This paper first reviews the design
      and architecture of the Flux Operator (Section 2), discussing Kubernetes
      abstractions for efficient networking and node setup. We then discuss how these
      design decisions impact essential needs such as workflows that use message
      passing interfaces (MPI), and experimental features like scaling and elasticity
      (Section 4). Finally, experimental work demonstrates the Flux Operator enable
      superior performance for a well-known HPC application over the MPI Operator, the
      primary available option at the time for running MPI workflows (Section 3). The
      paper concludes with discussion for anticipated future work, considerations for
      workflow design, and vision for the future (Section 5).
    questions_and_answers:
      - question: What is the Flux Operator?
        answer: |-
          A Kubernetes operator handling setup and configuration of complete Flux clusters
          in Kubernetes for efficiently managing HPC workloads.
      - question: What are the main sections in the Flux Operator paper?
        answer: |-
          That paper discusses the design and architecture, impact on workflows and features,
          expirimental and future work of the Flux Operator.
      - question: |-
          How does the Flux Operator compare to the MPI Operator?
        answer: |-
          It enables superior performance for well-known HPC applications.
  - context: |-
      The popularity and economic clout behind cloud computing presents a challenge
      for the high performance computing community -to resist new paradigms of cloud-
      native technologies and fall behind, losing talent and customers, or to embrace
      it, pursuing technological innovation, and viewing the shift as an opportunity
      for collaboration and growth. The latter approach, a movement identified as '
      converged computing ' is a good path to take, and this work represents an early
      start towards that desired future. The work here starts with one of the highest
      levels for running workflows -the orchestration tool -and has thought about the
      convergence of the HPC workload manager Flux Framework with the cloud
      orchestration framework Kubernetes. The Flux Operator is an example of
      convergence of technologies in this workload management space, and has
      demonstrated superior performance to the current equivalent in the space. In
      sharing this process of thinking about design to implementation, the authors of
      this paper hope to start discussion with the larger community that spans cloud
      and HPC for how to think about working on convergence for other types of
      software and technology. This work is a shining example of the collaboration and
      fun possible. The sharing of these results at Kubecon Amsterdam 23, ' 23
      inspired collaboration, discussion, and excitement about the converged computing
      movement. Projects and work are underway to address gaps that have been
      identified, and each a collaboration between computer scientists and cloud
      developers. The authors of this paper hope that this early work inspires, and
      allows for continued discussion for innovation in this space for not just
      workloads and scheduling, but also the challenges around it -storage, tenancy,
      and cost-estimation, among others. Through collaboration and creativity of
      design, pathways can be discovered for moving seamlessly between the spaces of
      cloud and HPC. Converged computing is a paradigm shift, and it s up to the HPC
      and ' cloud communtities to decide to embrace change and grow from it, or fight
      it off. This work chooses the first approach, and embraces it with hopes for a
      better future, and stronger more reproducible science.
    questions_and_answers:
      - question: |-
          What challenge does cloud computing present to HPC?
        answer: |-
          Either resist cloud-native paradigms and fall behind or embrace them as innovation opportunities.
      - question: |-
          What challenges must converged computing address?
        answer: |-
          Technical challenges (storage, multi-tenancy, cost), organizational collaboration between communities,
          and cultural reconciliation of performance vs. flexibility.
      - question: |-
          Why is converged computing a paradigm shift?
        answer: |-
          It reimagines HPC and cloud as complementary technologies,
          transforming scientific computing with combined performance and flexibility.
  - context: |-
      Running a single MiniCluster to create an isolated Flux cluster in Kubernetes is
      an initial step, but it is insufficient for realworld use cases of complex
      workflows. While it would be possible to shell into or otherwise interact with
      the cluster and run a workflow tool that implements Flux as an executor, 34 -36
      this also does not enable features needed for complex, heterogeneous workflows
      that might require different sizes or configurations of MiniClusters. We are
      considering integration of the MiniCluster custom resource definition as a
      first-class citizen into workflow tools in future work.
    questions_and_answers:
      - question: |-
          Why is a single MiniCluster insufficient for real use?
        answer: |-
          It lacks support for complex, heterogeneous workflows requiring different MiniCluster sizes or configurations.
      - question: |-
          What improvements are planned for MiniCluster?
        answer: |-
          Integrating MiniCluster custom resource definition as first-class citizen in workflow tools.
      - question: |-
          When would MiniCluster integration be beneficial?
        answer: |-
          It would enable features needed for complex, heterogeneous workflows with varied sizes and configurations.
  - context: |-
      To complete the early work in autoscaling, we considered the concept of
      bursting, 33 which means not just extending the size of a local cluster, but
      actually extending work to external resources. The bursting work for Flux would
      extend this approach to not just deploy external resources, but allow the lead
      broker to connect to brokers that are deployed in the other clusters. As an
      example, a Kubernetes cluster running on Google Cloud might burst to a cluster
      running on Compute Engine (CE), or to a cluster on Amazon Elastic Kubernetes
      Service (EKS).
    questions_and_answers:
      - question: |-
          What are examples of resources that a Kubernetes cluster
          running on Google Cloud might burst to?
        answer: |-
          Google Compute Engine or Amazon Elastic Kubernetes Service.
      - question: |-
          What benefits does Flux bursting provide?
        answer: |-
          Improved resource use, cost optimization,
          workload spike handling, and cross-provider portability.
      - question: |-
          What technical challenges does Flux bursting face?
        answer: |-
          Secure connectivity, network latency, data access,
          broker synchronization, and cross-cluster policy management.
  - context: |-
      The first requirement for using the Flux Operator is access to a Kubernetes
      cluster with sufficient permission to deploy each of the abstractions discussed
      in Section 2, including Deployment, Service, Job, and ConfigMap. The Flux
      Operator pre-built container images are provided for nodes with amd64 or arm64
      architectures. Operation comes down to deploying these objects with the kubectl
      command line tool and then using the same tool to deploy the MiniCluster CRD.
      Upon creation, the operator reconciles in a loop until the state of objects in
      Kubernetes matches the desired state specified in the CRD. This desired state
      encompasses the creation of the MiniCluster, which includes an indexed Job with
      a group of pods for the cluster, each containing a flux broker and volumes for
      configuration. A Headless Service networks the pods together to complete the
      MiniCluster. The specific attributes of the cluster (e.g., size, application
      image, command) can be customized in this YAML file, resulting in a Flux
      MiniCluster that exists to run a command and clean up (akin to a batch job), or
      an interactive cluster that can address several use cases and interactions
      discussed in Section 4. The final Flux MiniCluster is illustrated in Figure 1.
    questions_and_answers:
      - question: |-
          WWhat tool deploys Flux Operator objects?
        answer: |-
          kubectl, the standard Kubernetes command-line interface
          for deploying objects and the MiniCluster CRD.
      - question: |-
          What Kubernetes objects does Flux Operator deploy?
        answer: |-
          MiniCluster CRD, indexed Job with pods, Flux brokers with
          configuration volumes, and Headless Service network.
      - question: |-
          What are the main Flux MiniCluster use cases?
        answer: |-
          Ephemeral batch mode for specific workloads and
          interactive cluster mode for persistent environments, both customizable via YAML.
